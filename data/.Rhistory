load("~/Insofe/MiTh/data/.RData")
train_dummy$intr6 = train_dummy$Attr51 * train_dummy$Attr3 * train_dummy$Attr6
train_dummy$intr7 = train_dummy$Attr13 * train_dummy$Attr31 * train_dummy$Attr19 *
train_dummy$Attr23 * train_dummy$Attr42 * train_dummy$Attr43 * train_dummy$Attr44 *
train_dummy$Attr20 * train_dummy$Attr58 * train_dummy$Attr30 * train_dummy$Attr62
train_dummy$intr8 = train_dummy$Attr24 * train_dummy$Attr18 * train_dummy$Attr7 *
train_dummy$Attr14 * train_dummy$Attr35 * train_dummy$Attr11 * train_dummy$Attr22 *
train_dummy$Attr48 * train_dummy$Attr9 * train_dummy$Attr36
train_dummy$intr9 = train_dummy$Attr49 * train_dummy$Attr43 * train_dummy$Attr44 *
train_dummy$Attr20 * train_dummy$Attr58 * train_dummy$Attr30 * train_dummy$Attr62
train_dummy$intr9 = train_dummy$Attr56 * train_dummy$Attr49 * train_dummy$Attr43 * train_dummy$Attr44 *
train_dummy$Attr20 * train_dummy$Attr58 * train_dummy$Attr30 * train_dummy$Attr62
train_dummy$intr10 = train_dummy$Attr12 * train_dummy$Attr16 * train_dummy$Attr26
str(train_dummy)
train_dummy$target1 = train_dummy$target
train_dummy$target = NULL
str(train_dummy)
library(DMwR)
load("~/Insofe/MiTh/data/.RData")
library(C50)
library(rpart)
train_data = train_dummy
val_data = val_dummy
c50_model = C5.0(target1 ~., data = train_data, rules = T)
c50_val_class = predict(object = c50_model, newdata = val_data[, !colnames(val_data) %in% c('target1')])
confusionMatrix(c50_val_class, val_data$target1)
library(caret)
confusionMatrix(c50_val_class, val_data$target1)
getF1Stat(c50_val_class, val_data$target1)
c50_train_class = predict(object = c50_model,
newdata = newdata = train_data[, !colnames(train_data) %in% c('target1')])
c50_train_class = predict(object = c50_model,
newdata = train_data[, !colnames(train_data) %in% c('target1')])
rpart_train_class = predict(object = rpart_model, newdata = train_data, type='class')
rpart_model = rpart(target1 ~., data = train_data, method = 'class')
rpart_train_class = predict(object = rpart_model, newdata = train_data, type='class')
rpart_val_class = predict(object = rpart_model, newdata = val_data, type = 'class')
confusionMatrix(rpart_val_class, val_data$target1)
getF1Stat(rpart_val_class, val_data$target1)
library(randomForest)
rf_model = randomForest(target1 ~., data = train_data, keep.forest = T, ntree = 100)
rf_train_class = predict(object = rf_model,
newdata = train_data[, !colnames(train_data) %in% c('target1')],
norm.votes = T, type='response')
rf_val_class = predict(object = rf_model,
newdata = val_data[, !colnames(val_data) %in% c('target1')],
norm.votes = T, type = 'response')
getF1Stat(rf_val_class, val_data$target1)
confusionMatrix(rf_val_class, val_data$target1)
rf_tune_model = tuneRF(x = train_data[, !colnames(train_data) %in% c("target1")], y = train_data$target1,
stepFactor = 1.5, improve = 0.01, trace = T, plot = T, ntreeTry = 100)
rf_besttune_model = randomForest(target1~., data = train_data, mtry = best.m, importance = T, ntree = 100)
rf_tuned_train_class = predict(object = rf_besttune_model, train_data[, !colnames(train_data) %in% c('target1')],
type = 'response', norm.votes = T)
rf_tuned_val_class = predict(object = rf_besttune_model, newdata = val_data[, !colnames(val_data) %in% c('target1')],
type = 'response', norm.votes = T)
rf_tuned_imp_attr30 = as.character(rf_tuned_imp_attr[1:30, "Attribute"])
rf_tuned_imp_attr = data.frame(round(rf_besttune_model$importance[, 4], 2))
rf_tuned_imp_attr = data.frame(rownames(rf_tuned_imp_attr), rf_tuned_imp_attr[, 1])
colnames(rf_tuned_imp_attr) = c("Attribute", "Importance")
rf_tuned_imp_attr = rf_tuned_imp_attr[order(rf_tuned_imp_attr$Importance, decreasing = T), ]
rf_tuned_imp_attr30 = as.character(rf_tuned_imp_attr[1:30, "Attribute"])
rf_tuned_imp_attr30 = append(rf_tuned_imp_attr30, 'target1')
rf_besttune_topattr_model = randomForest(target1 ~., data = train_data[, rf_tuned_imp_attr30], mtry = best.m, importance = T, ntree = 100)
rf_tuned_topattr_train_class = predict(object = rf_besttune_topattr_model,
newdata = train_data[, rf_tuned_imp_attr30[-length(rf_tuned_imp_attr30)]],
type = 'response', norm.votes = T)
rf_tuned_topattr_val_class = predict(object = rf_besttune_topattr_model,
newdata = val_data[, rf_tuned_imp_attr30[-length(rf_tuned_imp_attr30)]],
type = 'response', norm.votes = T)
confusionMatrix(rf_tuned_val_class, val_data$target1)
getF1Stat(rf_tuned_val_class, val_data$target1)
rm(rf_tuned_imp_attr, rf_tuned_imp_attr30)
log_reg = glm(formula = target1 ~., data = train_data, family = 'binomial')
log_train_proba = predict(object = log_reg, type = 'response')
library(ROCR)
train_log_preds = prediction(log_train_proba, train_data$target1)
train_log_perf = performance(prediction.obj = train_log_preds, measure = 'tpr', x.measure = 'fpr')
plot(train_log_perf, col=rainbow(10), colorize=T, print.cutoffs.at=seq(0,1,0.05))
log_val_proba = predict(object = log_reg, newdata = val_data, type = 'response')
log_val_class = ifelse(log_val_proba > 0.5, 1, 0)
log_train_proba = predict(object = log_reg, newdata = train_data, type='response')
log_train_class = ifelse(log_train_proba > 0.5, 1, 0)
log_val_proba = predict(object = log_reg, newdata = val_data, type = 'response')
log_val_class = ifelse(log_val_proba > 0.5, 1, 0)
rm(train_log_preds, train_log_perf, train_auc_obj, basic_auc)
ada_train_pred = predict(object = ada_model, newdata = train_data[, !colnames(train_data)
%in% c('target1')])
train_preds_df <- data.frame(logistic = log_train_class, c50 = c50_train_class,
rpart = rpart_train_class, rf = rf_train_class,
rf_tuned = rf_tuned_train_class,
ada = ada_train_pred,
xgboost = xgb_train_pred, target1 = train_data$target1)
val_preds_df <- data.frame(logistic = log_val_class, c50 = c50_val_class,
rpart = rpart_val_class, rf = rf_val_class,
rf_tuned = rf_tuned_val_class,
ada = ada_val_pred,
xgboost = xgb_val_pred, target1 = val_data$target1)
stack_df <- rbind(train_preds_df, val_preds_df)
stack_df$target1 <- as.factor(stack_df$target1)
stack_df <- sapply(stack_df[, !(names(stack_df) %in% "target1")],
function(x) as.numeric(as.character(x)))
head(stack_df)
pca_stack <- prcomp(stack_df, scale = F)
head(pca_stack)
pca_stack$sdev
predicted_stack <- as.data.frame(predict(pca_stack, stack_df))[1:3]
head(predicted_stack)
str(stack_df)
train_preds_df <- data.frame(logistic = log_train_class, c50 = c50_train_class,
rpart = rpart_train_class, rf = rf_train_class,
rf_tuned = rf_tuned_train_class,
ada = ada_train_pred,
xgboost = xgb_train_pred, target1 = train_data$target1)
val_preds_df <- data.frame(logistic = log_val_class, c50 = c50_val_class,
rpart = rpart_val_class, rf = rf_val_class,
rf_tuned = rf_tuned_val_class,
ada = ada_val_pred,
xgboost = xgb_val_pred, target1 = val_data$target1)
stack_df <- rbind(train_preds_df, val_preds_df)
stack_df$target1 <- as.factor(stack_df$target1)
numeric_stack_df <- sapply(stack_df[, !(names(stack_df) %in% "target1")],
function(x) as.numeric(as.character(x)))
head(numeric_stack_df)
pca_stack <- prcomp(numeric_stack_df, scale = F)
pca_stack$sdev
predicted_stack <- as.data.frame(predict(pca_stack, numeric_stack_df))[1:3]
head(predicted_stack)
stacked_df <- data.frame(predicted_stack, target1 = stack_df$target1)
library(e1071)
library(kernlab)
stacked_model <- ksvm(target1 ~ . , stacked_df, kernel = "anovadot")
stacked_model
test_data = test_dummy
log_test_proba = predict(object = log_reg, newdata = test_data, type = 'response')
log_test_class = ifelse(log_test_proba > 0.5, 1, 0)
c50_test_class = predict(object = c50_model, newdata = test_data)
rpart_test_class = predict(object = rpart_model, newdata = test_data, type = 'class')
rf_test_class = predict(object = rf_model, newdata = test_data, type='response', norm.votes = T)
rf_tuned_test_class = predict(object = rf_besttune_model, newdata = test_data, type = 'response', norm.votes = T)
xg_params_test_proba = predict(object = xgb_model_with_params, newdata = as.matrix(test_data),
type='response', norm.votes = T)
xg_params_test_class = ifelse(xg_params_test_proba > 0.25, "1", "0")
ada_test_pred = predict(object = ada_model, newdata = test_data)
ada_test_class = predict(object = ada_model, newdata = test_data)
test_preds_df <- data.frame(logistic = log_test_class, c50 = c50_test_class,
rpart = rpart_test_class, rf = rf_test_class,
rf_tuned = rf_tuned_test_class,
ada = ada_test_class,
xgboost = xgb_test_class)
test_preds_df <- data.frame(logistic = log_test_class, c50 = c50_test_class,
rpart = rpart_test_class, rf = rf_test_class,
rf_tuned = rf_tuned_test_class,
ada = ada_test_class,
xgboost = xg_params_test_class)
rm(test_preds_df)
stack_df_test <- data.frame(logistic = log_test_class, c50 = c50_test_class,
rpart = rpart_test_class, rf = rf_test_class,
rf_tuned = rf_tuned_test_class,
ada = ada_test_class,
xgboost = xg_params_test_class)
numeric_st_df_test <- sapply(stack_df_test, function(x) as.numeric(as.character(x)))
predicted_stack_test <- as.data.frame(predict(pca_stack, numeric_st_df_test))[1:3]
preds_st_test <-  predict(stacked_model, predicted_stack_test)
rm(preds_st_test)
stacked_test_class <-  predict(stacked_model, predicted_stack_test)
table(stacked_test_class)
library(tidyverse)
train_dummy %>%
group_by(target) %>%
ggplot() +
geom_jitter(data = train_dummy %>%
group_by(target),
aes(x = target, y = Attr3, color = factor(target)),
position = position_jitter(w = 0.3, h = 0),
alpha = 0.5) +
geom_point(data = train_dummy %>%
group_by(target),
aes(x = target, y = Attr3, color = factor(target)),
size = 5, alpha = 0.2) +
labs(x = "Bankruptcy (0/1)",
y = "Working Capital / TotalAssets",
title = "Bankruptcy and Working Capital")
train_dummy %>%
group_by(target1) %>%
ggplot() +
geom_jitter(data = train_dummy %>%
group_by(target1),
aes(x = target1, y = Attr3, color = factor(target1)),
position = position_jitter(w = 0.3, h = 0),
alpha = 0.5) +
geom_point(data = train_dummy %>%
group_by(target1),
aes(x = target1, y = Attr3, color = factor(target1)),
size = 5, alpha = 0.2) +
labs(x = "Bankruptcy (0/1)",
y = "Working Capital / TotalAssets",
title = "Bankruptcy and Working Capital")
train_dummy %>%
ggplot(aes(x = Attr3)) +
geom_histogram()
train_dummy %>%
ggplot(aes(x = Attr27)) +
geom_histogram()
train_dummy %>%
ggplot(aes(y = Attr27)) +
geom_histogram()
train_dummy %>%
ggplot(aes(x = Attr27)) +
geom_bar()
train_dummy %>%
ggplot(aes(x = Attr27)) +
geom_histogram(binwidth = 1)
train_dummy %>%
ggplot(aes(x = Attr27)) +
geom_histogram(binwidth = 100)
hist(x = train_dummy$Attr27)
train_dummy %>%
ggplot(aes(x = Attr27)) +
geom_histogram()
qnorm(train_dummy$Attr27)
qqnorm(train_dummy$Attr27)
qqline(train_dummy$Attr27)
qqnorm(log(train_dummy$Attr27))
qqnorm(train_dummy$Attr27)
qqline(train_dummy$Attr27)
unique(train_dummy$Attr27)
install.packages("mlr")
train_data = train_dummy
val_data = val_dummy
train_auc_obj = performance(train_log_preds, measure = 'auc')
train_log_perf = performance(prediction.obj = train_log_preds, measure = 'tpr', x.measure = 'fpr')
train_log_preds = prediction(log_train_proba, train_data$target1)
train_log_perf = performance(prediction.obj = train_log_preds, measure = 'tpr', x.measure = 'fpr')
train_auc_obj = performance(train_log_preds, measure = 'auc')
basic_auc = train_auc_obj@y.values[[1]]
basic_auc
rm(train_log_preds, train_log_perf, train_auc_obj, basic_auc)
library(mlr)
train_task = makeClassifTask(data = train_data, target = 'target1')
val_task = makeClassifTask(data = val_data, target = 'target1')
train_task
train_task = makeClassifTask(data = train_data, target = 'target1', positive = '1')
train_task
val_task = makeClassifTask(data = val_data, target = 'target1', positive = '1')
train_task
getParamSet('classif.logistic')
getParamSet('classif.logreg')
getParamSet('classif.rpart')
log.learner = makeLearner("classif.logreg", predict.type = 'response')
crossval(learner = log.learner, task = train_task, iters = 5, stratify = T, measures = f1, show.info = T)
cv.log = crossval(learner = log.learner, task = train_task, iters = 5, stratify = T, measures = f1, show.info = T)
cv.log$aggr
log.model = train(learner = log.learner, task = train_task)
getLearnerModel(log.model)
log.train.class = predict(log.model, train_task)
log.train.class
log.train.class$data$response
log.val.class = predict(log.model, val_task)
library(caret)
confusionMatrix(as.factor(log.val.class$data$response), val_data$target1)
confusionMatrix(data = as.factor(log_val_class), reference = val_data$target1, positive = '0')
getF1Stat(as.factor(log.val.class$data$response), val_data$target1)
library(C50)
library(rpart)
listLearners(train_task)
c50.learner = makeLearner("classif.C50", predict.type = 'response')
getParamSet("classif.C50")
getParamSet("classif.rpart")
set_cv = makeResampleDesc(method = 'RepCV', reps = 10, folds = 4)
c50.params = makeParamSet(
makeIntegerParam("trails", lower = 1, upper = 10),
makeIntegerParam("CF", lower = 0.1, upper = 0.4))
gsControl = makeTuneControlGrid()
c50.tune = tuneParams(learner = c50.learner, task = train_task, resampling = set_cv,
measures = f1, par.set = c50.params, control = gs_control)
gs_control = makeTuneControlGrid()
rm(gsControl)
c50.tune = tuneParams(learner = c50.learner, task = train_task, resampling = set_cv,
measures = f1, par.set = c50.params, control = gs_control)
c50.params = makeParamSet(
makeIntegerParam("trails", lower = 1, upper = 10),
makeNumericParam("CF", lower = 0.1, upper = 0.4))
c50.tune = tuneParams(learner = c50.learner, task = train_task, resampling = set_cv,
measures = f1, par.set = c50.params, control = gs_control)
c50.params = makeParamSet(
makeNumericParam("CF", lower = 0.1, upper = 0.4))
c50.tune = tuneParams(learner = c50.learner, task = train_task, resampling = set_cv,
measures = f1, par.set = c50.params, control = gs_control)
set_cv = makeResampleDesc(method = 'CV', iters = 10) #reps = 10, folds = 4
c50.params = makeParamSet(
makeNumericParam("CF", lower = 0.1, upper = 0.4))
gs_control = makeTuneControlGrid()
c50.tune = tuneParams(learner = c50.learner, task = train_task, resampling = set_cv,
measures = f1, par.set = c50.params, control = gs_control)
c50.tune$x
c50.tune$y
c50.learner = setHyperPars(c50.learner, par.vals = c50.tune$x)
c50.train.class = predict(c50.learner, train_task)
c50.train = train(c50.learner, train_task)
c50.train = mlr::train(c50.learner, train_task)
c50.train.class = predict(c50.learner, train_task)
c50.train.class = predict(c50.train, train_task)
c50.val.class = predict(object = c50.train, val_task)
caret::confusionMatrix(as.factor(c50.val.class$data$response), val_data$target1)
getF1Stat(as.factor(c50.val.class$data$response), val_data$target1)
c50.params = makeParamSet(
makeNumericParam("CF", lower = 0.4, upper = 0.7))
c50.learner = makeLearner("classif.C50", predict.type = 'response')
set_cv = makeResampleDesc(method = 'CV', iters = 20) #reps = 10, folds = 4
c50.params = makeParamSet(
makeNumericParam("CF", lower = 0.4, upper = 0.7))
gs_control = makeTuneControlGrid()
c50.tune = tuneParams(learner = c50.learner, task = train_task, resampling = set_cv,
measures = f1, par.set = c50.params, control = gs_control)
c50.tune$x
c50.tune$y
c50.learner = setHyperPars(c50.learner, par.vals = c50.tune$x)
c50.train = mlr::train(c50.learner, train_task)
c50.train.class = predict(c50.train, train_task)
c50.val.class = predict(object = c50.train, val_task)
caret::confusionMatrix(as.factor(c50.val.class$data$response), val_data$target1)
getF1Stat(as.factor(c50.val.class$data$response), val_data$target1)
rpart.learner = makeLearner("classif.rpart", predict.type = 'response')
set_cv = makeResampleDesc(method = 'CV', iters = 20) #reps = 10, folds = 4
rpart.params = makeParamSet(makeIntegerParam("minsplit",lower = 10, upper = 50),
makeIntegerParam("minbucket", lower = 5, upper = 50),
makeNumericParam("cp", lower = 0.01, upper = 0.3))
raprt.tune = tuneParams(learner = rpart.learner, task = train_task, resampling = set_cv,
par.set = rpart.params, measures = f1, control = gs_control)
rpart.params = makeParamSet(makeIntegerParam("minsplit",lower = 10, upper = 50),
makeIntegerParam("minbucket", lower = 10, upper = 40),
makeNumericParam("cp", lower = 0.001, upper = 0.1))
raprt.tune = tuneParams(learner = rpart.learner, task = train_task, resampling = set_cv,
par.set = rpart.params, measures = f1, control = gs_control)
rpart.params = makeParamSet(makeIntegerParam("minsplit",lower = 10, upper = 50),
makeNumericParam("cp", lower = 0.0001, upper = 0.001))
raprt.tune = tuneParams(learner = rpart.learner, task = train_task, resampling = set_cv,
par.set = rpart.params, measures = f1, control = gs_control)
rpart.params = makeParamSet(makeIntegerParam("minsplit",lower = 30, upper = 50),
makeNumericParam("cp", lower = 0.0002, upper = 0.0003))
raprt.tune = tuneParams(learner = rpart.learner, task = train_task, resampling = set_cv,
par.set = rpart.params, measures = f1, control = gs_control)
rpart.learner = setHyperPars(learner = rpart.learner, par.vals = raprt.tune$x)
rpart.model = mlr::train(learner = rpart.learner, task = train_task)
getLearnerModel(rpart.model)
rpart.train = mlr::train(learner = rpart.learner, task = train_task)
rm(rpart.model)
rpart.val.class = predict(rpart.train, val_task)
rpart.train.class = predict(rpart.train, train_task)
caret::confusionMatrix(as.factor(rpart.val.class$data$response), val_data$target1)
getF1Stat(as.factor(rpart.val.class$data$response), val_data$target1)
library(randomForest)
getParamSet("classif.randomForest")
rf.learner = makeLearner('classif.randomforest', predict.type = 'response')
rf.learner = makeLearner('classif.randomForest', predict.type = 'response')
rancontrol <- makeTuneControlRandom(maxit = 70L)
rf.param <- makeParamSet(
makeIntegerParam("ntree",lower = 100, upper = 200),
makeIntegerParam("mtry", lower = 22, upper = 40)
)
rf.tune = tuneParams(learner = rf.learner, task = train_task, resampling = set_cv, measures = f1,
par.set = rf.param, control = rancontrol)
library(e1071)
library(caret)
library(kernlab)
train_data = train_dummy
val_data = val_dummy
library(mlr)
getParamSet("classif.ksvm")
rf.tune$x
data<-read.csv(file.choose())
load("~/Insofe/MiTh/data/.RData")
pure_data_file = read.csv(file = "dataset.csv", header = T) #na.strings = c(":", "?")
setwd("C:\\Users\\chait\\Documents\\Insofe\\MiTh\\data")
pure_data_file = read.csv(file = "dataset.csv", header = T) #na.strings = c(":", "?")
pure_data = pure_data_file[pure_data_file$istrain == 1, ]
library(caret)
colnames(train_dummy)
train_dummy %>%
group_by(target1) %>%
ggplot() +
geom_jitter(data = train_dummy %>%
group_by(target1),
aes(x = target1, y = workExp, color = factor(target1)),
position = position_jitter(w = 0.3, h = 0),
alpha = 0.5) +
geom_point(data = train_dummy %>%
group_by(target1),
aes(x = target1, y = workExp, color = factor(target1)),
size = 5, alpha = 0.2) +
labs(x = "Extra Hours(0/1)",
y = "YearsInCurrentRole",
title = "YearsInCurrentRole and Extra Hours")
library(tidyverse)
train_dummy %>%
group_by(target1) %>%
ggplot() +
geom_jitter(data = train_dummy %>%
group_by(target1),
aes(x = target1, y = workExp, color = factor(target1)),
position = position_jitter(w = 0.3, h = 0),
alpha = 0.5) +
geom_point(data = train_dummy %>%
group_by(target1),
aes(x = target1, y = workExp, color = factor(target1)),
size = 5, alpha = 0.2) +
labs(x = "Extra Hours(0/1)",
y = "YearsInCurrentRole",
title = "YearsInCurrentRole and Extra Hours")
summary(train_dummy$YearsInCurrentRole)
train_dummy %>%
group_by(target1) %>%
ggplot() +
geom_jitter(data = train_dummy %>%
group_by(target1),
aes(x = target1, y = workExp, color = factor(target1)),
position = position_jitter(w = 0.3, h = 0),
alpha = 0.5) +
geom_point(data = train_dummy %>%
group_by(target1),
aes(x = target1, y = workExp, color = factor(target1)),
size = 5, alpha = 0.2) +
labs(x = "Extra Hours(0/1)",
y = "WorkExp",
title = "WorkExp and Extra Hours")
train_dummy %>%
group_by(target1) %>%
ggplot() +
geom_jitter(data = train_dummy %>%
group_by(target1),
aes(x = target1, y = workExp, color = factor(target1)),
position = position_jitter(w = 0.3, h = 0),
alpha = 0.5) +
geom_point(data = train_dummy %>%
group_by(target1),
aes(x = target1, y = workExp, color = factor(target1)),
size = 5, alpha = 0.2) +
labs(x = "Extra Hours(0/1)",
y = "WorkExp (Days)",
title = "WorkExp and Extra Hours")
confusionMatrix(as.factor(xgb_val_pred), val_data_xgb_impattr$target1, positive = "1")
confusionMatrix(as.factor(xgb_val_pred), as.factor(val_data_xgb_impattr$target1), positive = "1")
